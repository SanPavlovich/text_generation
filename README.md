# text_generation
text generation based on statistics (n gram model)
Данная программа генерирует текст, основываясь на статистике встречающихся слов в большой базе обучающих текстов. К сожалению добиться какого-то адекватного результата
достаточно сложно, мой алгоритм вместо генерации осмысленных предложений выводит что-то в духе ААЭАЭАЭА, либо находит в обучающем тексте фрагмент и выводит уже его, что
больше походит не на процесс генерации, а на выдергивание фрагмента из текста. Я также пробовал учитывать контекст при генерации слов, то есть например по входной
цепочке слов word1 word2 ... word(n-1) word(n) считать возможные следующте слова после word1, word2, ... word(n-2) и возможные следующие слова после (word(n-1), word(n)).
Если множества этих слов пересекались, то из пересечения я брал рандомное слово и добавлял его в сгенерированную последовательность. Но к сожалению это не дало какого-то
адекватного результата, поэтому за неимением идей по улучшению этого алгоритма я хочу написать уже нейросетку.
